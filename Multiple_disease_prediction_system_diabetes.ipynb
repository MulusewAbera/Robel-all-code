{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnPbntVRnfvV"
      },
      "source": [
        "Importing the Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-71UtHzNVWjB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import tree\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import missingno as msno\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmfOfG8joBBy"
      },
      "source": [
        "Data Collection and Analysis\n",
        "\n",
        "PIMA Diabetes Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xpw6Mj_pn_TL"
      },
      "outputs": [],
      "source": [
        "# loading the diabetes dataset to a pandas DataFrame\n",
        "#diabetes_dataset = pd.read_csv('diabetes.csv')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "diabetes_dataset = pd.read_csv('/content/drive/MyDrive/diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the first 5 rows of the dataset\n",
        "diabetes_dataset.head()"
      ],
      "metadata": {
        "id": "-GFFDHCVMGbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Using dataframe diabetes_dataset:\n",
        "\n",
        "diabetes_dataset.hist()\n"
      ],
      "metadata": {
        "id": "aC7KPX2dMosg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of rows and Columns in this dataset\n",
        "diabetes_dataset.shape"
      ],
      "metadata": {
        "id": "KVeRxn1HMOBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the statistical measures of the data\n",
        "diabetes_dataset.describe()"
      ],
      "metadata": {
        "id": "9JDeRHZVMZjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyESnsuOG41P"
      },
      "outputs": [],
      "source": [
        "#count missing values\n",
        "missing_counts = diabetes_dataset.isnull().sum()\n",
        "print(missing_counts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Null Count Analysis Plot\n",
        "p = msno.bar(diabetes_dataset)"
      ],
      "metadata": {
        "id": "219S0l-JjbHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#letâ€™s check that how well our outcome column is balanced\n",
        "color_wheel = {0: \"blue\", 1: \"red\"}\n",
        "colors = diabetes_dataset[\"Outcome\"].map(lambda x: color_wheel.get(x))\n",
        "print(diabetes_dataset.Outcome.value_counts())\n",
        "p = diabetes_dataset.Outcome.value_counts().plot(kind=\"bar\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mrf6cpIFhxXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB1qRaNcqeh5"
      },
      "source": [
        "0 --> Non-Diabetic\n",
        "\n",
        "1 --> Diabetic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoDW7l9mqqHZ"
      },
      "outputs": [],
      "source": [
        "# separating the data and labels\n",
        "X = diabetes_dataset.drop(columns = 'Outcome', axis=1)\n",
        "Y = diabetes_dataset['Outcome']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate Correlation Matrix:\n",
        "correlation_matrix = X.corr()\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "id": "QApI-UKGAL1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate correlation matrix\n",
        "plt.figure(figsize=(10,7))\n",
        "sn.heatmap(correlation_matrix, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BWxJ2echFmC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eiRW9M9raMm"
      },
      "outputs": [],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoxgTJAMrcCl"
      },
      "outputs": [],
      "source": [
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHciEFkxsoQP"
      },
      "source": [
        "Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEfKGj_yslvD"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, stratify=Y, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR05T-o0t3FQ"
      },
      "outputs": [],
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElJ3tkOtuC_n"
      },
      "source": [
        "Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5szLWHlNt9xc"
      },
      "outputs": [],
      "source": [
        "modelsvm = svm.SVC(kernel='rbf',gamma='scale')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncJWY_7suPAb"
      },
      "outputs": [],
      "source": [
        "#training the support vector Machine Classifier\n",
        "modelsvm.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "frjXA23rbD30"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV4-CAfquiyP"
      },
      "source": [
        "**Model Evaluation and Accuracy Score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJLEPQK7ueXp"
      },
      "outputs": [],
      "source": [
        "# accuracy score on the training data of support vector Machine Classifier\n",
        "X_train_prediction = modelsvm.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "print('Accuracy score of the training data SVM: ', training_data_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy score on the test data of support vector Machine Classifier\n",
        "X_test_prediction = modelsvm.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "print('Accuracy score of the test data SVM : ', test_data_accuracy)"
      ],
      "metadata": {
        "id": "Ez2fOkGvba3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn_x9C17hwbi"
      },
      "outputs": [],
      "source": [
        "cmSVM = confusion_matrix(Y_test, X_test_prediction)\n",
        "cmSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0GVWek0h1-3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "sn.heatmap(cmSVM, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke-yBIXvls6o"
      },
      "outputs": [],
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(Y_test, X_test_prediction)\n",
        "print(f\"Precision for your SVM model:\",precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-BwNjN1p54q"
      },
      "outputs": [],
      "source": [
        "# Calculate recall\n",
        "recall = recall_score(Y_test, X_test_prediction)\n",
        "print(f\"recall for your SVM model:\",recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrMQmBOAsbVz"
      },
      "outputs": [],
      "source": [
        "# Calculate f1_score\n",
        "f1 = f1_score(Y_test, X_test_prediction)\n",
        "print(\"f1_score for your SVM model:\",f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVm model performance using cross_val_score\n",
        "cross_val_score(SVC(gamma='auto'), X, Y,cv=3)"
      ],
      "metadata": {
        "id": "cwL9DVOHH3hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z22Q-vAFJ5OT"
      },
      "source": [
        "**Training the Model Decision tree Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF4uBUU2NAlf"
      },
      "outputs": [],
      "source": [
        "modelDT = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=4)\n",
        "modelDT.fit(X_train, Y_train)\n",
        "#training the Decition tree Classifier\n",
        "#model.score(inputs_n,target)\n",
        "# accuracy score on the training data\n",
        "X_train_prediction = modelDT.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "print('Accuracy score of the training data DT: ', training_data_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50pfxWbyM66B"
      },
      "source": [
        "**Model Evaluation Accuracy Score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoE9ROgsNyrg"
      },
      "outputs": [],
      "source": [
        "# accuracy score on the test data of Decition tree Classifier\n",
        "X_test_prediction = modelDT.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "print('Accuracy score of the test data DT: ', test_data_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhuBYtAkg_hy"
      },
      "outputs": [],
      "source": [
        "cmDT = confusion_matrix(Y_test, X_test_prediction)\n",
        "cmDT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6Pln8GShKGF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "sn.heatmap(cmDT, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH1Og12znZmv"
      },
      "outputs": [],
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(Y_test, X_test_prediction)\n",
        "print(f\"Precision for your DT model:\",precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwdf0-7rqbp4"
      },
      "outputs": [],
      "source": [
        "# Calculate recall\n",
        "recall = recall_score(Y_test, X_test_prediction)\n",
        "print(f\"recall for your DT model:\",recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T82vK-hs3b-"
      },
      "outputs": [],
      "source": [
        "# Calculate f1_score\n",
        "f1 = f1_score(Y_test, X_test_prediction)\n",
        "print(\"f1_score for your DT model:\",f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision tree model performance using cross_val_score\n",
        "cross_val_score(DecisionTreeClassifier(max_depth=40), X, Y, cv=3)"
      ],
      "metadata": {
        "id": "2d-4lc1iJgZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKdgWmE5Kavv"
      },
      "source": [
        "**training the Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj86DSilNLsB"
      },
      "outputs": [],
      "source": [
        "modelLR = LogisticRegression()\n",
        "#training the Logistic Regression\n",
        "modelLR.fit(X_train, Y_train)\n",
        "# accuracy score on the training data\n",
        "#model.score(X_test,y_test)\n",
        "#y_predicted = model.predict(X_test)\n",
        "#model.predict_proba(X_test)\n",
        "X_train_prediction = modelLR.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "print('Accuracy score of the training data LR: ', training_data_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI8dJCzrPjTW"
      },
      "outputs": [],
      "source": [
        "# accuracy score on the test data of Logistic Regression\n",
        "X_test_prediction = modelLR.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "print('Accuracy score of the test data LR: ', test_data_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_x0A_i3hViy"
      },
      "outputs": [],
      "source": [
        "cmLR = confusion_matrix(Y_test, X_test_prediction)\n",
        "cmLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAO5IJIhhWVd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "sn.heatmap(cmLR, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0jIUP6HoiVT"
      },
      "outputs": [],
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(Y_test, X_test_prediction)\n",
        "print(f\"Precision for your LR model:\",precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-naMGAJqg2J"
      },
      "outputs": [],
      "source": [
        "# Calculate recall\n",
        "recall = recall_score(Y_test, X_test_prediction)\n",
        "print(f\"recall for your LR model:\",recall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkw-jWo2s8Mq"
      },
      "outputs": [],
      "source": [
        "# Calculate f1_score\n",
        "f1 = f1_score(Y_test, X_test_prediction)\n",
        "print(\"f1_score for your LR model:\",f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic regression model performance using cross_val_score\n",
        "cross_val_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X, Y,cv=3)"
      ],
      "metadata": {
        "id": "0g0RkvU6GXrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-PlappKKmGp"
      },
      "source": [
        "**training the K_Nereast_Neighbors  Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_kfccQeNZay"
      },
      "outputs": [],
      "source": [
        "modelKNN = KNeighborsClassifier(n_neighbors=10)\n",
        "modelKNN.fit(X_train, Y_train)\n",
        "#training the K_Nereast_Neighbors  Classifier\n",
        "#knn.score(X_test, Y_test)\n",
        "X_train_prediction = modelKNN.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "print('Accuracy score of the training data KNN : ', training_data_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40kC_d2FR-kf"
      },
      "outputs": [],
      "source": [
        "# accuracy score on the test data ofK_Nereast_Neighbors  Classifier\n",
        "X_test_prediction = modelKNN.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "print('Accuracy score of the test data KNN : ', test_data_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gii3OsmvgIcc"
      },
      "outputs": [],
      "source": [
        "cmKNN = confusion_matrix(Y_test, X_test_prediction)\n",
        "cmKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRdJjr0UgWgR"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "sn.heatmap(cmKNN, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk4JDQTvonF_"
      },
      "outputs": [],
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(Y_test, X_test_prediction)\n",
        "print(f\"Precision for your KNN model:\",precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd0FvbUFqk05"
      },
      "outputs": [],
      "source": [
        "# Calculate recall\n",
        "recall = recall_score(Y_test, X_test_prediction)\n",
        "print(f\"recall for your KNN model:\",recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkMj3JOWtRgh"
      },
      "outputs": [],
      "source": [
        "# Calculate f1_score\n",
        "f1 = f1_score(Y_test, X_test_prediction)\n",
        "print(\"f1_score for your KNN model:\",f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#K_ Nearest Neighbors model performance using cross_val_score\n",
        "cross_val_score(KNeighborsClassifier(n_neighbors=5), X, Y, cv=3)"
      ],
      "metadata": {
        "id": "2i8g-mOMNBab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7lU5VONKvHR"
      },
      "source": [
        "**training the Random forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxmzyxQ8Ny6B"
      },
      "outputs": [],
      "source": [
        "modelRF = RandomForestClassifier(n_estimators=20, max_depth=150)\n",
        "modelRF.fit(X_train, Y_train)\n",
        "#training the Random forest Classifier\n",
        "X_train_prediction = modelRF.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "print('Accuracy score of the training data RF : ', training_data_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxa7QdcFS_lf"
      },
      "outputs": [],
      "source": [
        "# accuracy score on the test data of Random forest Classifier\n",
        "X_test_prediction = modelRF.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "print('Accuracy score of the test data RF : ', test_data_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkBmhyXpcviN"
      },
      "outputs": [],
      "source": [
        "cmRF = confusion_matrix(Y_test, X_test_prediction)\n",
        "cmRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiWjIlNudTFS"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "sn.heatmap(cmRF, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ftaAmNtouUu"
      },
      "outputs": [],
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(Y_test, X_test_prediction)\n",
        "print(f\"Precision for your RF model:\",precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLo_MEfQq0RA"
      },
      "outputs": [],
      "source": [
        "# Calculate recall\n",
        "recall = recall_score(Y_test, X_test_prediction)\n",
        "print(f\"recall for your RF model:\",recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFw0Tj1itaux"
      },
      "outputs": [],
      "source": [
        "# Calculate f1_score\n",
        "f1 = f1_score(Y_test, X_test_prediction)\n",
        "print(\"f1_score for your RF model:\",f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest model performance using cross_val_score\n",
        "cross_val_score(RandomForestClassifier(n_estimators=40), X, Y,cv=3)"
      ],
      "metadata": {
        "id": "gtrBrYoSJvVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDDM8lzvK6u-"
      },
      "source": [
        "**training the Gradient Boosting Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7KkOaethvt7"
      },
      "outputs": [],
      "source": [
        "modelGB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1)\n",
        "modelGB.fit(X_train, Y_train)\n",
        "#training the Gradient Boosting Classifier\n",
        "X_train_prediction = modelGB.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "print('Accuracy score of the training data GB: ', training_data_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2AJed-IVbP-"
      },
      "outputs": [],
      "source": [
        "# accuracy score on the test data of Gradient Boosting Classifier\n",
        "X_test_prediction = modelGB.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "print('Accuracy score of the test data GB: ', test_data_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtj7HxkCiHrk"
      },
      "outputs": [],
      "source": [
        "cmGB = confusion_matrix(Y_test, X_test_prediction)\n",
        "cmGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOC2IEjciIKC"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "sn.heatmap(cmGB, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6smt0kP6ozqV"
      },
      "outputs": [],
      "source": [
        "# Calculate precision\n",
        "precision = precision_score(Y_test, X_test_prediction)\n",
        "print(f\"Precision for your GB model:\",precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo_5hMMHq5-m"
      },
      "outputs": [],
      "source": [
        "# Calculate recall\n",
        "recall = recall_score(Y_test, X_test_prediction)\n",
        "print(f\"recall for your GB model:\",recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2z2E9MXtp0F"
      },
      "outputs": [],
      "source": [
        "# Calculate f1_score\n",
        "f1 = f1_score(Y_test, X_test_prediction)\n",
        "print(\"f1_score for your GB model:\",f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient Boosting  model performance using cross_val_score\n",
        "cross_val_score(GradientBoostingClassifier(n_estimators=100, learning_rate=0.1), X, Y, cv=3)"
      ],
      "metadata": {
        "id": "ljP1mIrVODZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq8ZX1xpwPF5"
      },
      "source": [
        "Making a Predictive System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-ULRe4yv5tH"
      },
      "outputs": [],
      "source": [
        "input_data = (5,166,72,19,175,25.8,0.587,51)\n",
        "\n",
        "# changing the input_data to numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the array as we are predicting for one instance\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "prediction = modelsvm.predict(input_data_reshaped)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "  print('The person is not diabetic')\n",
        "else:\n",
        "  print('The person is diabetic')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCHCMHpshHU4"
      },
      "source": [
        "Saving the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdmTOR4MhHCB"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gN09lokhKuZ"
      },
      "outputs": [],
      "source": [
        "filename = 'diabetes_model.sav'\n",
        "pickle.dump(modelsvm, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKW4D5CqhP5X"
      },
      "outputs": [],
      "source": [
        "# loading the saved model\n",
        "loaded_model = pickle.load(open('diabetes_model.sav', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exbg9-VWiHRx"
      },
      "outputs": [],
      "source": [
        "input_data = (5,166,72,19,175,25.8,0.587,51)\n",
        "\n",
        "# changing the input_data to numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the array as we are predicting for one instance\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "prediction = loaded_model.predict(input_data_reshaped)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "  print('The person is not diabetic')\n",
        "else:\n",
        "  print('The person is diabetic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP-TYuEFOTF4"
      },
      "outputs": [],
      "source": [
        "for column in X.columns:\n",
        "  print(column)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "LIFCoFdWeVTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "LPVQ9zi0e-Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KBHiy6XgfWPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "S-VC2RRjffCn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}